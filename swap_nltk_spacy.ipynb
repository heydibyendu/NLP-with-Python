{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the document is 383.\n"
     ]
    }
   ],
   "source": [
    "document = open(\"reutersDataset/reut2-001.sgm\", 'r')\n",
    "text = document.read()\n",
    "document.close()\n",
    "document_beautiful = BeautifulSoup(text, \"html.parser\")\n",
    "for reuter in document_beautiful.find_all(\"reuters\"):\n",
    "    text1 = reuter.find('text')\n",
    "    title = text1.title\n",
    "    doc = text1.body\n",
    "    if doc!=None:\n",
    "        doc_len = len(doc.text.split())\n",
    "        if (doc_len> 200):\n",
    "            print(f\"The length of the document is {doc_len}.\")\n",
    "            #print(\"=================================\")\n",
    "            break\n",
    "article = doc.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp1 = spacy.load('en_core_web_sm')\n",
    "\n",
    "#-- Creating SpaCy object\n",
    "doc = nlp1(article)\n",
    "labels = [x.label_ for x in doc.ents]\n",
    "Counter(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 46 entities in the article and they are represented as 9 unique labels.\n"
     ]
    }
   ],
   "source": [
    "print('There are %s entities in the article and they are represented as %s unique labels.' %(len(doc.ents), 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Article: Unilever Plc <UN.A> and NV group reported\n",
      "improvements in margins and underlying sales volume growth of\n",
      "five pct in 1986 after stripping out the effects of falling\n",
      "prices, disposals and currency movements, Unilever Plc chairman\n",
      "Michael Angus said.\n",
      "    He told reporters that volumes in North America increased\n",
      "some 10.5 pct while European consumer goods rose about 2.5 pct\n",
      "after being flat for some years.\n",
      "    Much of the disposal strategy, aimed at concentrating\n",
      "activities on core businesses, had now been completed, he\n",
      "noted.\n",
      "    But the process of acquisitions would go on, with strategic\n",
      "acquisitions taking place \"from time to time,\" he said.\n",
      "    The company earlier reported a 20 pct rise in pre-tax\n",
      "profits for 1986 to 1.14 billion stg from 953 mln previously.\n",
      "In guilder terms, however, profits at the pre-tax level dropped\n",
      "three pct to 3.69 billion from 3.81 billion.\n",
      "    Angus said the recent purchase of Chesebrough-Pond's Inc\n",
      "<CBM.N> for 72.50 dlrs a share was unlikely to bring any\n",
      "earnings dilution.\n",
      "    However, it would not add much to profits, with much of the\n",
      "company's operating profits paying for the acquisition costs.\n",
      "    Finance director Niall Fitzgerald added that while gearing\n",
      "- debt to equity plus debt - rose to about 60 pct at end 1986\n",
      "from 35 pct last year, this was expected to drop back to about\n",
      "40 pct by end-1987.\n",
      "    The same divergence was made in full year dividend, with\n",
      "Unilever NV's rising 3.4 pct to 15.33 guilders and Unilever\n",
      "Plc's increasing 29.9 pct to 50.17p, approximately in line with\n",
      "the change in attributable profit.\n",
      "    Angus said the prospectus for the sale of parts of\n",
      "Chesebrough was due to be published shortly. However, he said\n",
      "that there was no target date for completing the process.\n",
      "    He also declined to say what sort of sum Unilever hoped to\n",
      "realise from the operation, beyond noting that Chesebrough had\n",
      "paid around 1.25 billion dlrs for Stauffer Chemical Co, which\n",
      "operates outside Unilever's core activities.\n",
      "    In the U.S., Organic growth from the Lipton Foods business,\n",
      "considerable expansion in the household products business and\n",
      "in margarine had been behind the overall sales increase.\n",
      "    However, he noted that the U.S. Household products business\n",
      "had turned in a planned loss, with fourth quarter performance\n",
      "better than expected despite the anticipated heavy launch costs\n",
      "of its Surf detergents.\n",
      " Reuter\n",
      "\u0003\n",
      "\n",
      "Original: Unilever Plc, New: Unilever Plc, Labels: ORG\n",
      "Original: NV, New: NV, Labels: ORG\n",
      "Original: five, New: five, Labels: CARDINAL\n",
      "Original: 1986, New: 1986, Labels: DATE\n",
      "Original: Unilever Plc, New: Unilever Plc, Labels: ORG\n",
      "Original: Michael Angus, New: Michael Angus, Labels: PERSON\n",
      "Original: North America, New: North America, Labels: LOC\n",
      "Original: 10.5, New: 10.5, Labels: CARDINAL\n",
      "Original: European, New: european, Labels: NORP\n",
      "Original: about 2.5, New: about 2.5, Labels: CARDINAL\n",
      "Original: some years, New: some year, Labels: DATE\n",
      "Original: 20, New: 20, Labels: CARDINAL\n",
      "Original: 1986, New: 1986, Labels: DATE\n",
      "Original: 1.14 billion, New: 1.14 billion, Labels: CARDINAL\n",
      "Original: 953, New: 953, Labels: CARDINAL\n",
      "Original: three, New: three, Labels: CARDINAL\n",
      "Original: 3.69 billion, New: 3.69 billion, Labels: CARDINAL\n",
      "Original: 3.81 billion, New: 3.81 billion, Labels: CARDINAL\n",
      "Original: Angus, New: Angus, Labels: PERSON\n",
      "Original: Chesebrough-Pond's Inc\n",
      "<, New: Chesebrough - Pond 's Inc \n",
      " <, Labels: ORG\n",
      "Original: 72.50, New: 72.50, Labels: CARDINAL\n",
      "Original: Niall Fitzgerald, New: Niall Fitzgerald, Labels: PERSON\n",
      "Original: about 60, New: about 60, Labels: CARDINAL\n",
      "Original: 1986, New: 1986, Labels: DATE\n",
      "Original: 35, New: 35, Labels: CARDINAL\n",
      "Original: last year, New: last year, Labels: DATE\n",
      "Original: end-1987, New: end-1987, Labels: DATE\n",
      "Original: full year, New: full year, Labels: DATE\n",
      "Original: 3.4, New: 3.4, Labels: CARDINAL\n",
      "Original: 15.33 guilders, New: 15.33 guilde, Labels: MONEY\n",
      "Original: Unilever\n",
      "Plc's, New: Unilever \n",
      " Plc 's, Labels: ORG\n",
      "Original: 29.9, New: 29.9, Labels: CARDINAL\n",
      "Original: 50.17p, New: 50.17p, Labels: CARDINAL\n",
      "Original: Angus, New: Angus, Labels: PERSON\n",
      "Original: Unilever, New: Unilever, Labels: ORG\n",
      "Original: Chesebrough, New: Chesebrough, Labels: ORG\n",
      "Original: around 1.25 billion, New: around 1.25 billion, Labels: MONEY\n",
      "Original: Stauffer Chemical Co, New: Stauffer Chemical Co, Labels: ORG\n",
      "Original: Unilever, New: Unilever, Labels: ORG\n",
      "Original: U.S., New: U.S., Labels: GPE\n",
      "Original: Organic, New: organic, Labels: ORG\n",
      "Original: Lipton Foods, New: Lipton Foods, Labels: ORG\n",
      "Original: U.S. Household, New: U.S. Household, Labels: ORG\n",
      "Original: fourth quarter, New: fourth quarter, Labels: DATE\n",
      "Original: Surf, New: Surf, Labels: PRODUCT\n",
      "Original: Reuter\n",
      ", New: Reuter, Labels: PERSON\n"
     ]
    }
   ],
   "source": [
    "#-- Printing the original document\n",
    "print('Original Article: %s' % (doc))\n",
    "print()\n",
    "\n",
    "#-- Creating the tokens with lemmanization and labels\n",
    "for ent in doc.ents:\n",
    "    print('Original: %s, New: %s, Labels: %s' %(ent.text, ent.lemma_, ent.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: Unilever, POS: PROPN\n",
      "Token: Plc, POS: PROPN\n",
      "Token: <, POS: X\n",
      "Token: un.a, POS: X\n",
      "Token: >, POS: X\n",
      "Token: and, POS: CCONJ\n",
      "Token: NV, POS: PROPN\n",
      "Token: group, POS: NOUN\n",
      "Token: report, POS: VERB\n",
      "Token: \n",
      ", POS: SPACE\n",
      "Token: improvement, POS: NOUN\n",
      "Token: in, POS: ADP\n",
      "Token: margin, POS: NOUN\n",
      "Token: and, POS: CCONJ\n",
      "Token: underlie, POS: VERB\n",
      "Token: sale, POS: NOUN\n",
      "Token: volume, POS: NOUN\n",
      "Token: growth, POS: NOUN\n",
      "Token: of, POS: ADP\n",
      "Token: \n",
      ", POS: SPACE\n",
      "Token: five, POS: NUM\n",
      "Token: pct, POS: NOUN\n",
      "Token: in, POS: ADP\n",
      "Token: 1986, POS: NUM\n",
      "Token: after, POS: ADP\n",
      "Token: strip, POS: VERB\n",
      "Token: out, POS: ADP\n",
      "Token: the, POS: DET\n",
      "Token: effect, POS: NOUN\n",
      "Token: of, POS: ADP\n",
      "Token: fall, POS: VERB\n",
      "Token: \n",
      ", POS: SPACE\n",
      "Token: price, POS: NOUN\n",
      "Token: ,, POS: PUNCT\n",
      "Token: disposal, POS: NOUN\n",
      "Token: and, POS: CCONJ\n",
      "Token: currency, POS: NOUN\n",
      "Token: movement, POS: NOUN\n",
      "Token: ,, POS: PUNCT\n",
      "Token: Unilever, POS: PROPN\n",
      "Token: Plc, POS: PROPN\n",
      "Token: chairman, POS: NOUN\n",
      "Token: \n",
      ", POS: SPACE\n",
      "Token: Michael, POS: PROPN\n",
      "Token: Angus, POS: PROPN\n",
      "Token: say, POS: VERB\n",
      "Token: ., POS: PUNCT\n",
      "Token: \n",
      "    , POS: SPACE\n",
      "Token: -PRON-, POS: PRON\n",
      "Token: tell, POS: VERB\n",
      "Token: reporter, POS: NOUN\n",
      "Token: that, POS: SCONJ\n",
      "Token: volume, POS: NOUN\n",
      "Token: in, POS: ADP\n",
      "Token: North, POS: PROPN\n",
      "Token: America, POS: PROPN\n",
      "Token: increase, POS: VERB\n",
      "Token: \n",
      ", POS: SPACE\n",
      "Token: some, POS: DET\n",
      "Token: 10.5, POS: NUM\n",
      "Token: pct, POS: INTJ\n",
      "Token: while, POS: SCONJ\n",
      "Token: european, POS: ADJ\n",
      "Token: consumer, POS: NOUN\n",
      "Token: good, POS: NOUN\n",
      "Token: rise, POS: VERB\n",
      "Token: about, POS: ADV\n",
      "Token: 2.5, POS: NUM\n",
      "Token: pct, POS: PROPN\n",
      "Token: \n",
      ", POS: SPACE\n",
      "Token: after, POS: ADP\n",
      "Token: be, POS: AUX\n",
      "Token: flat, POS: ADJ\n",
      "Token: for, POS: ADP\n",
      "Token: some, POS: DET\n",
      "Token: year, POS: NOUN\n",
      "Token: ., POS: PUNCT\n",
      "Token: \n",
      "    , POS: SPACE\n",
      "Token: much, POS: ADJ\n",
      "Token: of, POS: ADP\n",
      "Token: the, POS: DET\n",
      "Token: disposal, POS: NOUN\n",
      "Token: strategy, POS: NOUN\n",
      "Token: ,, POS: PUNCT\n",
      "Token: aim, POS: VERB\n",
      "Token: at, POS: ADP\n",
      "Token: concentrate, POS: VERB\n",
      "Token: \n",
      ", POS: SPACE\n",
      "Token: activity, POS: NOUN\n",
      "Token: on, POS: ADP\n",
      "Token: core, POS: NOUN\n",
      "Token: business, POS: NOUN\n",
      "Token: ,, POS: PUNCT\n",
      "Token: have, POS: AUX\n",
      "Token: now, POS: ADV\n",
      "Token: be, POS: AUX\n",
      "Token: complete, POS: VERB\n",
      "Token: ,, POS: PUNCT\n",
      "Token: -PRON-, POS: PRON\n",
      "Token: \n",
      ", POS: SPACE\n",
      "Token: note, POS: VERB\n",
      "Token: ., POS: PUNCT\n",
      "Token: \n",
      "    , POS: SPACE\n",
      "Token: but, POS: CCONJ\n",
      "Token: the, POS: DET\n",
      "Token: process, POS: NOUN\n",
      "Token: of, POS: ADP\n",
      "Token: acquisition, POS: NOUN\n",
      "Token: would, POS: AUX\n",
      "Token: go, POS: VERB\n",
      "Token: on, POS: ADP\n",
      "Token: ,, POS: PUNCT\n",
      "Token: with, POS: ADP\n",
      "Token: strategic, POS: ADJ\n",
      "Token: \n",
      ", POS: SPACE\n",
      "Token: acquisition, POS: NOUN\n",
      "Token: take, POS: VERB\n",
      "Token: place, POS: NOUN\n",
      "Token: \", POS: PUNCT\n",
      "Token: from, POS: ADP\n",
      "Token: time, POS: NOUN\n",
      "Token: to, POS: ADP\n",
      "Token: time, POS: NOUN\n",
      "Token: ,, POS: PUNCT\n",
      "Token: \", POS: PUNCT\n",
      "Token: -PRON-, POS: PRON\n",
      "Token: say, POS: VERB\n",
      "Token: ., POS: PUNCT\n",
      "Token: \n",
      "    , POS: SPACE\n",
      "Token: the, POS: DET\n",
      "Token: company, POS: NOUN\n",
      "Token: earlier, POS: ADV\n",
      "Token: report, POS: VERB\n",
      "Token: a, POS: DET\n",
      "Token: 20, POS: NUM\n",
      "Token: pct, POS: PROPN\n",
      "Token: rise, POS: NOUN\n",
      "Token: in, POS: ADP\n",
      "Token: pre, POS: ADJ\n",
      "Token: -, POS: ADJ\n",
      "Token: tax, POS: ADJ\n",
      "Token: \n",
      ", POS: SPACE\n",
      "Token: profit, POS: NOUN\n",
      "Token: for, POS: ADP\n",
      "Token: 1986, POS: NUM\n",
      "Token: to, POS: ADP\n",
      "Token: 1.14, POS: NUM\n",
      "Token: billion, POS: NUM\n",
      "Token: stg, POS: NOUN\n",
      "Token: from, POS: ADP\n",
      "Token: 953, POS: NUM\n",
      "Token: mln, POS: NOUN\n",
      "Token: previously, POS: ADV\n",
      "Token: ., POS: PUNCT\n",
      "Token: \n",
      ", POS: SPACE\n",
      "Token: in, POS: ADP\n",
      "Token: guilder, POS: ADJ\n",
      "Token: term, POS: NOUN\n",
      "Token: ,, POS: PUNCT\n",
      "Token: however, POS: ADV\n",
      "Token: ,, POS: PUNCT\n",
      "Token: profit, POS: NOUN\n",
      "Token: at, POS: ADP\n",
      "Token: the, POS: DET\n",
      "Token: pre, POS: ADJ\n",
      "Token: -, POS: ADJ\n",
      "Token: tax, POS: ADJ\n",
      "Token: level, POS: NOUN\n",
      "Token: drop, POS: VERB\n",
      "Token: \n",
      ", POS: SPACE\n",
      "Token: three, POS: NUM\n",
      "Token: pct, POS: NOUN\n",
      "Token: to, POS: ADP\n",
      "Token: 3.69, POS: NUM\n",
      "Token: billion, POS: NUM\n",
      "Token: from, POS: ADP\n",
      "Token: 3.81, POS: NUM\n",
      "Token: billion, POS: NUM\n",
      "Token: ., POS: PUNCT\n",
      "Token: \n",
      "    , POS: SPACE\n",
      "Token: Angus, POS: PROPN\n",
      "Token: say, POS: VERB\n",
      "Token: the, POS: DET\n",
      "Token: recent, POS: ADJ\n",
      "Token: purchase, POS: NOUN\n",
      "Token: of, POS: ADP\n",
      "Token: Chesebrough, POS: PROPN\n",
      "Token: -, POS: PUNCT\n",
      "Token: Pond, POS: PROPN\n",
      "Token: 's, POS: PART\n",
      "Token: Inc, POS: PROPN\n",
      "Token: \n",
      ", POS: SPACE\n",
      "Token: <, POS: X\n",
      "Token: cbm.n, POS: NOUN\n",
      "Token: >, POS: X\n",
      "Token: for, POS: ADP\n",
      "Token: 72.50, POS: NUM\n",
      "Token: dlrs, POS: NOUN\n",
      "Token: a, POS: DET\n",
      "Token: share, POS: NOUN\n",
      "Token: be, POS: AUX\n",
      "Token: unlikely, POS: ADJ\n",
      "Token: to, POS: PART\n",
      "Token: bring, POS: VERB\n",
      "Token: any, POS: DET\n",
      "Token: \n",
      ", POS: SPACE\n",
      "Token: earning, POS: NOUN\n",
      "Token: dilution, POS: NOUN\n",
      "Token: ., POS: PUNCT\n",
      "Token: \n",
      "    , POS: SPACE\n",
      "Token: however, POS: ADV\n",
      "Token: ,, POS: PUNCT\n",
      "Token: -PRON-, POS: PRON\n",
      "Token: would, POS: AUX\n",
      "Token: not, POS: PART\n",
      "Token: add, POS: VERB\n",
      "Token: much, POS: ADJ\n",
      "Token: to, POS: ADP\n",
      "Token: profit, POS: NOUN\n",
      "Token: ,, POS: PUNCT\n",
      "Token: with, POS: ADP\n",
      "Token: much, POS: ADJ\n",
      "Token: of, POS: ADP\n",
      "Token: the, POS: DET\n",
      "Token: \n",
      ", POS: SPACE\n",
      "Token: company, POS: NOUN\n",
      "Token: 's, POS: PART\n",
      "Token: operating, POS: NOUN\n",
      "Token: profit, POS: NOUN\n",
      "Token: pay, POS: VERB\n",
      "Token: for, POS: ADP\n",
      "Token: the, POS: DET\n",
      "Token: acquisition, POS: NOUN\n",
      "Token: cost, POS: NOUN\n",
      "Token: ., POS: PUNCT\n",
      "Token: \n",
      "    , POS: SPACE\n",
      "Token: finance, POS: NOUN\n",
      "Token: director, POS: NOUN\n",
      "Token: Niall, POS: PROPN\n",
      "Token: Fitzgerald, POS: PROPN\n",
      "Token: add, POS: VERB\n",
      "Token: that, POS: SCONJ\n",
      "Token: while, POS: SCONJ\n",
      "Token: gear, POS: VERB\n",
      "Token: \n",
      ", POS: SPACE\n",
      "Token: -, POS: PUNCT\n",
      "Token: debt, POS: NOUN\n",
      "Token: to, POS: ADP\n",
      "Token: equity, POS: NOUN\n",
      "Token: plus, POS: CCONJ\n",
      "Token: debt, POS: NOUN\n",
      "Token: -, POS: PUNCT\n",
      "Token: rise, POS: VERB\n",
      "Token: to, POS: ADP\n",
      "Token: about, POS: ADV\n",
      "Token: 60, POS: NUM\n",
      "Token: pct, POS: NOUN\n",
      "Token: at, POS: ADP\n",
      "Token: end, POS: NOUN\n",
      "Token: 1986, POS: NUM\n",
      "Token: \n",
      ", POS: SPACE\n",
      "Token: from, POS: ADP\n",
      "Token: 35, POS: NUM\n",
      "Token: pct, POS: NOUN\n",
      "Token: last, POS: ADJ\n",
      "Token: year, POS: NOUN\n",
      "Token: ,, POS: PUNCT\n",
      "Token: this, POS: DET\n",
      "Token: be, POS: AUX\n",
      "Token: expect, POS: VERB\n",
      "Token: to, POS: PART\n",
      "Token: drop, POS: VERB\n",
      "Token: back, POS: ADV\n",
      "Token: to, POS: ADP\n",
      "Token: about, POS: ADP\n",
      "Token: \n",
      ", POS: SPACE\n",
      "Token: 40, POS: NUM\n",
      "Token: pct, POS: PROPN\n",
      "Token: by, POS: ADP\n",
      "Token: end-1987, POS: NOUN\n",
      "Token: ., POS: PUNCT\n",
      "Token: \n",
      "    , POS: SPACE\n",
      "Token: the, POS: DET\n",
      "Token: same, POS: ADJ\n",
      "Token: divergence, POS: NOUN\n",
      "Token: be, POS: AUX\n",
      "Token: make, POS: VERB\n",
      "Token: in, POS: ADP\n",
      "Token: full, POS: ADJ\n",
      "Token: year, POS: NOUN\n",
      "Token: dividend, POS: NOUN\n",
      "Token: ,, POS: PUNCT\n",
      "Token: with, POS: ADP\n",
      "Token: \n",
      ", POS: SPACE\n",
      "Token: Unilever, POS: PROPN\n",
      "Token: NV, POS: PROPN\n",
      "Token: 's, POS: PART\n",
      "Token: rise, POS: VERB\n",
      "Token: 3.4, POS: NUM\n",
      "Token: pct, POS: NOUN\n",
      "Token: to, POS: ADP\n",
      "Token: 15.33, POS: NUM\n",
      "Token: guilde, POS: NOUN\n",
      "Token: and, POS: CCONJ\n",
      "Token: Unilever, POS: PROPN\n",
      "Token: \n",
      ", POS: SPACE\n",
      "Token: Plc, POS: PROPN\n",
      "Token: 's, POS: PART\n",
      "Token: increase, POS: VERB\n",
      "Token: 29.9, POS: NUM\n",
      "Token: pct, POS: NOUN\n",
      "Token: to, POS: ADP\n",
      "Token: 50.17p, POS: PROPN\n",
      "Token: ,, POS: PUNCT\n",
      "Token: approximately, POS: ADV\n",
      "Token: in, POS: ADP\n",
      "Token: line, POS: NOUN\n",
      "Token: with, POS: ADP\n",
      "Token: \n",
      ", POS: SPACE\n",
      "Token: the, POS: DET\n",
      "Token: change, POS: NOUN\n",
      "Token: in, POS: ADP\n",
      "Token: attributable, POS: ADJ\n",
      "Token: profit, POS: NOUN\n",
      "Token: ., POS: PUNCT\n",
      "Token: \n",
      "    , POS: SPACE\n",
      "Token: Angus, POS: PROPN\n",
      "Token: say, POS: VERB\n",
      "Token: the, POS: DET\n",
      "Token: prospectus, POS: NOUN\n",
      "Token: for, POS: ADP\n",
      "Token: the, POS: DET\n",
      "Token: sale, POS: NOUN\n",
      "Token: of, POS: ADP\n",
      "Token: part, POS: NOUN\n",
      "Token: of, POS: ADP\n",
      "Token: \n",
      ", POS: SPACE\n",
      "Token: Chesebrough, POS: PROPN\n",
      "Token: be, POS: AUX\n",
      "Token: due, POS: ADJ\n",
      "Token: to, POS: PART\n",
      "Token: be, POS: AUX\n",
      "Token: publish, POS: VERB\n",
      "Token: shortly, POS: ADV\n",
      "Token: ., POS: PUNCT\n",
      "Token: however, POS: ADV\n",
      "Token: ,, POS: PUNCT\n",
      "Token: -PRON-, POS: PRON\n",
      "Token: say, POS: VERB\n",
      "Token: \n",
      ", POS: SPACE\n",
      "Token: that, POS: SCONJ\n",
      "Token: there, POS: PRON\n",
      "Token: be, POS: AUX\n",
      "Token: no, POS: DET\n",
      "Token: target, POS: NOUN\n",
      "Token: date, POS: NOUN\n",
      "Token: for, POS: ADP\n",
      "Token: complete, POS: VERB\n",
      "Token: the, POS: DET\n",
      "Token: process, POS: NOUN\n",
      "Token: ., POS: PUNCT\n",
      "Token: \n",
      "    , POS: SPACE\n",
      "Token: -PRON-, POS: PRON\n",
      "Token: also, POS: ADV\n",
      "Token: decline, POS: VERB\n",
      "Token: to, POS: PART\n",
      "Token: say, POS: VERB\n",
      "Token: what, POS: PRON\n",
      "Token: sort, POS: NOUN\n",
      "Token: of, POS: ADP\n",
      "Token: sum, POS: NOUN\n",
      "Token: Unilever, POS: PROPN\n",
      "Token: hope, POS: VERB\n",
      "Token: to, POS: ADP\n",
      "Token: \n",
      ", POS: SPACE\n",
      "Token: realise, POS: VERB\n",
      "Token: from, POS: ADP\n",
      "Token: the, POS: DET\n",
      "Token: operation, POS: NOUN\n",
      "Token: ,, POS: PUNCT\n",
      "Token: beyond, POS: ADP\n",
      "Token: note, POS: VERB\n",
      "Token: that, POS: SCONJ\n",
      "Token: Chesebrough, POS: PROPN\n",
      "Token: have, POS: AUX\n",
      "Token: \n",
      ", POS: SPACE\n",
      "Token: pay, POS: VERB\n",
      "Token: around, POS: ADP\n",
      "Token: 1.25, POS: NUM\n",
      "Token: billion, POS: NUM\n",
      "Token: dlr, POS: NOUN\n",
      "Token: for, POS: ADP\n",
      "Token: Stauffer, POS: PROPN\n",
      "Token: Chemical, POS: PROPN\n",
      "Token: Co, POS: PROPN\n",
      "Token: ,, POS: PUNCT\n",
      "Token: which, POS: PRON\n",
      "Token: \n",
      ", POS: SPACE\n",
      "Token: operate, POS: VERB\n",
      "Token: outside, POS: ADP\n",
      "Token: Unilever, POS: PROPN\n",
      "Token: 's, POS: PART\n",
      "Token: core, POS: NOUN\n",
      "Token: activity, POS: NOUN\n",
      "Token: ., POS: PUNCT\n",
      "Token: \n",
      "    , POS: SPACE\n",
      "Token: in, POS: ADP\n",
      "Token: the, POS: DET\n",
      "Token: U.S., POS: PROPN\n",
      "Token: ,, POS: PUNCT\n",
      "Token: organic, POS: ADJ\n",
      "Token: growth, POS: NOUN\n",
      "Token: from, POS: ADP\n",
      "Token: the, POS: DET\n",
      "Token: Lipton, POS: PROPN\n",
      "Token: Foods, POS: PROPN\n",
      "Token: business, POS: NOUN\n",
      "Token: ,, POS: PUNCT\n",
      "Token: \n",
      ", POS: SPACE\n",
      "Token: considerable, POS: ADJ\n",
      "Token: expansion, POS: NOUN\n",
      "Token: in, POS: ADP\n",
      "Token: the, POS: DET\n",
      "Token: household, POS: NOUN\n",
      "Token: product, POS: NOUN\n",
      "Token: business, POS: NOUN\n",
      "Token: and, POS: CCONJ\n",
      "Token: \n",
      ", POS: SPACE\n",
      "Token: in, POS: ADP\n",
      "Token: margarine, POS: NOUN\n",
      "Token: have, POS: AUX\n",
      "Token: be, POS: AUX\n",
      "Token: behind, POS: ADP\n",
      "Token: the, POS: DET\n",
      "Token: overall, POS: ADJ\n",
      "Token: sale, POS: NOUN\n",
      "Token: increase, POS: NOUN\n",
      "Token: ., POS: PUNCT\n",
      "Token: \n",
      "    , POS: SPACE\n",
      "Token: however, POS: ADV\n",
      "Token: ,, POS: PUNCT\n",
      "Token: -PRON-, POS: PRON\n",
      "Token: note, POS: VERB\n",
      "Token: that, POS: SCONJ\n",
      "Token: the, POS: DET\n",
      "Token: U.S., POS: PROPN\n",
      "Token: Household, POS: PROPN\n",
      "Token: product, POS: NOUN\n",
      "Token: business, POS: NOUN\n",
      "Token: \n",
      ", POS: SPACE\n",
      "Token: have, POS: AUX\n",
      "Token: turn, POS: VERB\n",
      "Token: in, POS: ADP\n",
      "Token: a, POS: DET\n",
      "Token: plan, POS: VERB\n",
      "Token: loss, POS: NOUN\n",
      "Token: ,, POS: PUNCT\n",
      "Token: with, POS: ADP\n",
      "Token: fourth, POS: ADJ\n",
      "Token: quarter, POS: NOUN\n",
      "Token: performance, POS: NOUN\n",
      "Token: \n",
      ", POS: SPACE\n",
      "Token: well, POS: ADJ\n",
      "Token: than, POS: SCONJ\n",
      "Token: expect, POS: VERB\n",
      "Token: despite, POS: SCONJ\n",
      "Token: the, POS: DET\n",
      "Token: anticipated, POS: ADJ\n",
      "Token: heavy, POS: ADJ\n",
      "Token: launch, POS: NOUN\n",
      "Token: cost, POS: NOUN\n",
      "Token: \n",
      ", POS: SPACE\n",
      "Token: of, POS: ADP\n",
      "Token: -PRON-, POS: PRON\n",
      "Token: Surf, POS: PROPN\n",
      "Token: detergent, POS: NOUN\n",
      "Token: ., POS: PUNCT\n",
      "Token: \n",
      " , POS: SPACE\n",
      "Token: Reuter, POS: PROPN\n",
      "Token: \n",
      ", POS: SPACE\n",
      "Token: \u0003, POS: X\n"
     ]
    }
   ],
   "source": [
    "#-- Creating tokens with parts of speech\n",
    "for ent in doc:\n",
    "    print('Token: %s, POS: %s' %(ent.lemma_, ent.pos_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\heydi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unilever', 'Plc', '<', 'UN.A', '>', 'and', 'NV', 'group', 'reported', 'improvements', 'in', 'margins', 'and', 'underlying', 'sales', 'volume', 'growth', 'of', 'five', 'pct', 'in', '1986', 'after', 'stripping', 'out', 'the', 'effects', 'of', 'falling', 'prices', ',', 'disposals', 'and', 'currency', 'movements', ',', 'Unilever', 'Plc', 'chairman', 'Michael', 'Angus', 'said', '.', 'He', 'told', 'reporters', 'that', 'volumes', 'in', 'North', 'America', 'increased', 'some', '10.5', 'pct', 'while', 'European', 'consumer', 'goods', 'rose', 'about', '2.5', 'pct', 'after', 'being', 'flat', 'for', 'some', 'years', '.', 'Much', 'of', 'the', 'disposal', 'strategy', ',', 'aimed', 'at', 'concentrating', 'activities', 'on', 'core', 'businesses', ',', 'had', 'now', 'been', 'completed', ',', 'he', 'noted', '.', 'But', 'the', 'process', 'of', 'acquisitions', 'would', 'go', 'on', ',', 'with', 'strategic', 'acquisitions', 'taking', 'place', '``', 'from', 'time', 'to', 'time', ',', \"''\", 'he', 'said', '.', 'The', 'company', 'earlier', 'reported', 'a', '20', 'pct', 'rise', 'in', 'pre-tax', 'profits', 'for', '1986', 'to', '1.14', 'billion', 'stg', 'from', '953', 'mln', 'previously', '.', 'In', 'guilder', 'terms', ',', 'however', ',', 'profits', 'at', 'the', 'pre-tax', 'level', 'dropped', 'three', 'pct', 'to', '3.69', 'billion', 'from', '3.81', 'billion', '.', 'Angus', 'said', 'the', 'recent', 'purchase', 'of', 'Chesebrough-Pond', \"'s\", 'Inc', '<', 'CBM.N', '>', 'for', '72.50', 'dlrs', 'a', 'share', 'was', 'unlikely', 'to', 'bring', 'any', 'earnings', 'dilution', '.', 'However', ',', 'it', 'would', 'not', 'add', 'much', 'to', 'profits', ',', 'with', 'much', 'of', 'the', 'company', \"'s\", 'operating', 'profits', 'paying', 'for', 'the', 'acquisition', 'costs', '.', 'Finance', 'director', 'Niall', 'Fitzgerald', 'added', 'that', 'while', 'gearing', '-', 'debt', 'to', 'equity', 'plus', 'debt', '-', 'rose', 'to', 'about', '60', 'pct', 'at', 'end', '1986', 'from', '35', 'pct', 'last', 'year', ',', 'this', 'was', 'expected', 'to', 'drop', 'back', 'to', 'about', '40', 'pct', 'by', 'end-1987', '.', 'The', 'same', 'divergence', 'was', 'made', 'in', 'full', 'year', 'dividend', ',', 'with', 'Unilever', 'NV', \"'s\", 'rising', '3.4', 'pct', 'to', '15.33', 'guilders', 'and', 'Unilever', 'Plc', \"'s\", 'increasing', '29.9', 'pct', 'to', '50.17p', ',', 'approximately', 'in', 'line', 'with', 'the', 'change', 'in', 'attributable', 'profit', '.', 'Angus', 'said', 'the', 'prospectus', 'for', 'the', 'sale', 'of', 'parts', 'of', 'Chesebrough', 'was', 'due', 'to', 'be', 'published', 'shortly', '.', 'However', ',', 'he', 'said', 'that', 'there', 'was', 'no', 'target', 'date', 'for', 'completing', 'the', 'process', '.', 'He', 'also', 'declined', 'to', 'say', 'what', 'sort', 'of', 'sum', 'Unilever', 'hoped', 'to', 'realise', 'from', 'the', 'operation', ',', 'beyond', 'noting', 'that', 'Chesebrough', 'had', 'paid', 'around', '1.25', 'billion', 'dlrs', 'for', 'Stauffer', 'Chemical', 'Co', ',', 'which', 'operates', 'outside', 'Unilever', \"'s\", 'core', 'activities', '.', 'In', 'the', 'U.S.', ',', 'Organic', 'growth', 'from', 'the', 'Lipton', 'Foods', 'business', ',', 'considerable', 'expansion', 'in', 'the', 'household', 'products', 'business', 'and', 'in', 'margarine', 'had', 'been', 'behind', 'the', 'overall', 'sales', 'increase', '.', 'However', ',', 'he', 'noted', 'that', 'the', 'U.S.', 'Household', 'products', 'business', 'had', 'turned', 'in', 'a', 'planned', 'loss', ',', 'with', 'fourth', 'quarter', 'performance', 'better', 'than', 'expected', 'despite', 'the', 'anticipated', 'heavy', 'launch', 'costs', 'of', 'its', 'Surf', 'detergents', '.', 'Reuter', '\\x03']\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "wordnet_lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "tokens2 = nltk.word_tokenize(article)\n",
    "print(tokens2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: improvements, New: improvement\n",
      "Original: margins, New: margin\n",
      "Original: sales, New: sale\n",
      "Original: effects, New: effect\n",
      "Original: prices, New: price\n",
      "Original: disposals, New: disposal\n",
      "Original: movements, New: movement\n",
      "Original: reporters, New: reporter\n",
      "Original: volumes, New: volume\n",
      "Original: goods, New: good\n",
      "Original: years, New: year\n",
      "Original: activities, New: activity\n",
      "Original: businesses, New: business\n",
      "Original: acquisitions, New: acquisition\n",
      "Original: acquisitions, New: acquisition\n",
      "Original: profits, New: profit\n",
      "Original: terms, New: term\n",
      "Original: profits, New: profit\n",
      "Original: was, New: wa\n",
      "Original: profits, New: profit\n",
      "Original: profits, New: profit\n",
      "Original: costs, New: cost\n",
      "Original: was, New: wa\n",
      "Original: was, New: wa\n",
      "Original: guilders, New: guilder\n",
      "Original: parts, New: part\n",
      "Original: was, New: wa\n",
      "Original: was, New: wa\n",
      "Original: activities, New: activity\n",
      "Original: products, New: product\n",
      "Original: sales, New: sale\n",
      "Original: products, New: product\n",
      "Original: costs, New: cost\n",
      "Original: its, New: it\n",
      "Original: detergents, New: detergent\n"
     ]
    }
   ],
   "source": [
    "for token in tokens2:\n",
    "    lemmatized_token = wordnet_lemmatizer.lemmatize(token)    \n",
    "    if token != lemmatized_token:\n",
    "        print('Original: %s, New: %s' % (token, lemmatized_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Unilever', 'NNP'),\n",
       " ('Plc', 'NNP'),\n",
       " ('<', 'NNP'),\n",
       " ('UN.A', 'NNP'),\n",
       " ('>', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('NV', 'NNP'),\n",
       " ('group', 'NN'),\n",
       " ('reported', 'VBD'),\n",
       " ('improvements', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('margins', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('underlying', 'JJ'),\n",
       " ('sales', 'NNS'),\n",
       " ('volume', 'NN'),\n",
       " ('growth', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('five', 'CD'),\n",
       " ('pct', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('1986', 'CD'),\n",
       " ('after', 'IN'),\n",
       " ('stripping', 'VBG'),\n",
       " ('out', 'RP'),\n",
       " ('the', 'DT'),\n",
       " ('effects', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('falling', 'VBG'),\n",
       " ('prices', 'NNS'),\n",
       " (',', ','),\n",
       " ('disposals', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('currency', 'NN'),\n",
       " ('movements', 'NNS'),\n",
       " (',', ','),\n",
       " ('Unilever', 'NNP'),\n",
       " ('Plc', 'NNP'),\n",
       " ('chairman', 'NN'),\n",
       " ('Michael', 'NNP')]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sent = nltk.pos_tag(tokens2)\n",
    "tagged_sent[:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
